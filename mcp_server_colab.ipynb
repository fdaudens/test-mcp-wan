{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# MCP Server in Google Colab\n",
    "\n",
    "This notebook demonstrates how to run an authenticated MCP (Model Context Protocol) server in Google Colab.\n",
    "\n",
    "## Features\n",
    "- OpenAI Vector Store search and fetch\n",
    "- Google Fact Check API integration\n",
    "- RSS feed fetching (BBC Technology)\n",
    "- Guardian API search\n",
    "- Authentication support (currently disabled for demo)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install mcp[server]>=1.0.0b6 fastapi>=0.110.0 uvicorn[standard]>=0.27.0 openai>=1.40.0 pydantic>=2.7.0 PyJWT[crypto]>=2.8.0 httpx>=0.27.0 python-dotenv>=1.0.1 feedparser>=6.0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "env_setup"
   },
   "source": [
    "## Environment Configuration\n",
    "\n",
    "Set your API keys and configuration below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "env_vars"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API keys here\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "os.environ[\"VECTOR_STORE_ID\"] = \"your-vector-store-id-here\"\n",
    "os.environ[\"GOOGLE_FACT_CHECK_API_KEY\"] = \"your-google-fact-check-api-key-here\"\n",
    "os.environ[\"GUARDIAN_API_KEY\"] = \"your-guardian-api-key-here\"\n",
    "\n",
    "# Server configuration\n",
    "os.environ[\"PORT\"] = \"8788\"\n",
    "os.environ[\"AUTH0_ISSUER\"] = \"https://dev-65wmmp5d56ev40iy.us.auth0.com/\"\n",
    "os.environ[\"REQUIRED_SCOPES\"] = \"user\"\n",
    "\n",
    "print(\"Environment variables set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports_cell"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "import datetime as dt\n",
    "import httpx\n",
    "import feedparser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pydantic import AnyHttpUrl\n",
    "\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from mcp.server.auth.provider import AccessToken, TokenVerifier\n",
    "from mcp.server.auth.settings import AuthSettings\n",
    "\n",
    "load_dotenv()\n",
    "print(\"Dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_cell"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PORT = int(os.getenv(\"PORT\", \"8788\"))\n",
    "RESOURCE_SERVER_URL = os.getenv(\"RESOURCE_SERVER_URL\", f\"http://localhost:{PORT}/\")\n",
    "AUTH_ISSUER = os.getenv(\"AUTH0_ISSUER\", \"https://dev-65wmmp5d56ev40iy.us.auth0.com/\")\n",
    "REQUIRED_SCOPES = os.getenv(\"REQUIRED_SCOPES\", \"user\").split(\",\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "VECTOR_STORE_ID = os.getenv(\"VECTOR_STORE_ID\")\n",
    "GOOGLE_FACT_CHECK_API_KEY = os.getenv(\"GOOGLE_FACT_CHECK_API_KEY\")\n",
    "GUARDIAN_API_KEY = os.getenv(\"GUARDIAN_API_KEY\")\n",
    "\n",
    "print(f\"Server will run on port {PORT}\")\n",
    "print(f\"OpenAI API Key configured: {bool(OPENAI_API_KEY)}\")\n",
    "print(f\"Vector Store ID configured: {bool(VECTOR_STORE_ID)}\")\n",
    "print(f\"Google Fact Check API Key configured: {bool(GOOGLE_FACT_CHECK_API_KEY)}\")\n",
    "print(f\"Guardian API Key configured: {bool(GUARDIAN_API_KEY)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auth"
   },
   "source": [
    "## Authentication Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auth_cell"
   },
   "outputs": [],
   "source": [
    "# Simple token verifier (replace with real validation in production)\n",
    "class SimpleTokenVerifier(TokenVerifier):\n",
    "    async def verify_token(self, token: str) -> AccessToken | None:\n",
    "        # TODO: verify signature, issuer, expiry, audience/resource, scopes, etc.\n",
    "        return AccessToken(\n",
    "            token=token or \"dev_token\",\n",
    "            client_id=\"dev_client\",\n",
    "            subject=\"dev\",\n",
    "            scopes=REQUIRED_SCOPES,\n",
    "            claims={\"debug\": True},\n",
    "        )\n",
    "\n",
    "print(\"Authentication verifier configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcp_setup"
   },
   "source": [
    "## MCP Server Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcp_cell"
   },
   "outputs": [],
   "source": [
    "# FastMCP server (no FastAPI/Uvicorn needed)\n",
    "mcp = FastMCP(\n",
    "    name=\"python-authenticated-mcp\",\n",
    "    instructions=\"Authenticated MCP server in Python. Implements `search` and `fetch` with OpenAI Vector Stores.\",\n",
    "    # Authentication disabled for demo\n",
    "    # If you prefer stateless requests, set stateless_http=True\n",
    "    # token_verifier=SimpleTokenVerifier(),\n",
    "    # auth=AuthSettings(\n",
    "    #     issuer_url=AnyHttpUrl(AUTH_ISSUER),\n",
    "    #     resource_server_url=AnyHttpUrl(RESOURCE_SERVER_URL),\n",
    "    #     required_scopes=REQUIRED_SCOPES,\n",
    "    # ),\n",
    ")\n",
    "\n",
    "# Mount Streamable HTTP at a dedicated path to avoid conflicts with root\n",
    "mcp.settings.streamable_http_path = \"/sse\"\n",
    "\n",
    "print(\"MCP server configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tools_header"
   },
   "source": [
    "## MCP Tools Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "openai_tools"
   },
   "source": [
    "### OpenAI Vector Store Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "openai_client"
   },
   "outputs": [],
   "source": [
    "def _openai_client() -> OpenAI:\n",
    "    # If OPENAI_API_KEY is unset, OpenAI() will use env/ambient config if available.\n",
    "    return OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else OpenAI()\n",
    "\n",
    "print(\"OpenAI client helper configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search_tool"
   },
   "outputs": [],
   "source": [
    "@mcp.tool()\n",
    "async def search(query: str) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search for documents in the configured OpenAI Vector Store.\n",
    "    Returns: {\"results\": [{\"id\",\"title\",\"text\",\"url\"}...]}\n",
    "    \"\"\"\n",
    "    results: list[dict[str, str]] = []\n",
    "    if not query or not query.strip() or not VECTOR_STORE_ID:\n",
    "        return {\"results\": results}\n",
    "\n",
    "    client = _openai_client()\n",
    "\n",
    "    try:\n",
    "        # Prefer the current signature\n",
    "        resp = client.vector_stores.search(\n",
    "            VECTOR_STORE_ID,\n",
    "            {\"query\": query, \"ranking_options\": {\"score_threshold\": 0.5}, \"rewrite_query\": True},\n",
    "        )\n",
    "        data = getattr(resp, \"data\", None) or []\n",
    "    except Exception:\n",
    "        # Fallback to keyword args in case of SDK shape differences\n",
    "        try:\n",
    "            resp = client.vector_stores.search(\n",
    "                vector_store_id=VECTOR_STORE_ID,\n",
    "                query=query,\n",
    "                ranking_options={\"score_threshold\": 0.5},\n",
    "                rewrite_query=True,\n",
    "            )\n",
    "            data = getattr(resp, \"data\", None) or []\n",
    "        except Exception:\n",
    "            data = []\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        file_id = getattr(item, \"file_id\", None) or getattr(item, \"id\", None) or f\"vs_{i}\"\n",
    "        filename = getattr(item, \"filename\", None) or f\"Document {i+1}\"\n",
    "        content_list = getattr(item, \"content\", None) or []\n",
    "        text_content = \"\"\n",
    "        if content_list:\n",
    "            first = content_list[0]\n",
    "            if isinstance(first, dict) and \"text\" in first:\n",
    "                text_content = first.get(\"text\") or \"\"\n",
    "            elif isinstance(first, str):\n",
    "                text_content = first\n",
    "        text_snippet = (text_content[:200] + \"...\") if len(text_content) > 200 else (text_content or \"No content available\")\n",
    "        results.append(\n",
    "            {\n",
    "                \"id\": str(file_id),\n",
    "                \"title\": str(filename),\n",
    "                \"text\": text_snippet,\n",
    "                \"url\": f\"https://platform.openai.com/storage/files/{file_id}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "print(\"Search tool registered!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fetch_tool"
   },
   "outputs": [],
   "source": [
    "@mcp.tool()\n",
    "async def fetch(id: str) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch full content of a document by file ID from the OpenAI Vector Store.\n",
    "    Returns: {\"id\",\"title\",\"text\",\"url\",\"metadata\":optional}\n",
    "    \"\"\"\n",
    "    client = _openai_client()\n",
    "    title = f\"Document {id}\"\n",
    "    metadata: Any = None\n",
    "    full_text = \"No content available.\"\n",
    "\n",
    "    if not id or not VECTOR_STORE_ID:\n",
    "        return {\"id\": id, \"title\": title, \"text\": full_text, \"url\": f\"https://platform.openai.com/storage/files/{id}\", \"metadata\": metadata}\n",
    "\n",
    "    try:\n",
    "        # Retrieve content chunks\n",
    "        content_resp = client.vector_stores.files.content(id, {\"vector_store_id\": VECTOR_STORE_ID})\n",
    "        parts: list[str] = []\n",
    "        for item in getattr(content_resp, \"data\", None) or []:\n",
    "            if isinstance(item, dict) and \"text\" in item:\n",
    "                parts.append(str(item.get(\"text\") or \"\"))\n",
    "        if parts:\n",
    "            full_text = \"\\n\".join(parts)\n",
    "\n",
    "        # Optionally improve title/metadata\n",
    "        try:\n",
    "            file_info = client.vector_stores.files.retrieve(vector_store_id=VECTOR_STORE_ID, file_id=id)\n",
    "            filename = getattr(file_info, \"filename\", None)\n",
    "            if filename:\n",
    "                title = filename\n",
    "            attrs = getattr(file_info, \"attributes\", None)\n",
    "            if attrs:\n",
    "                metadata = attrs\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return {\"id\": id, \"title\": title, \"text\": full_text, \"url\": f\"https://platform.openai.com/storage/files/{id}\", \"metadata\": metadata}\n",
    "\n",
    "print(\"Fetch tool registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fact_check_tools"
   },
   "source": [
    "### Google Fact Check Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fact_check_tool"
   },
   "outputs": [],
   "source": [
    "@mcp.tool()\n",
    "async def fact_check_search(\n",
    "    query: str,\n",
    "    language_code: str | None = \"en\",\n",
    "    page_size: int = 10,\n",
    "    page_token: str | None = None,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search for fact checks using Google's Fact Check Tools API.\n",
    "    Returns: {\"results\": [{\"text\",\"claimant\",\"claimDate\",\"reviews\":[{\"publisher\",\"url\",\"title\",\"reviewDate\",\"textualRating\",\"languageCode\"}]}], \"nextPageToken\": optional}\n",
    "\n",
    "    Notes:\n",
    "    - Requires the env var GOOGLE_FACT_CHECK_API_KEY to be set.\n",
    "    - Accepts optional language code and pagination.\n",
    "    \"\"\"\n",
    "    results: list[dict[str, Any]] = []\n",
    "\n",
    "    if not query or not query.strip():\n",
    "        return {\"results\": results}\n",
    "\n",
    "    api_key = GOOGLE_FACT_CHECK_API_KEY or os.getenv(\"GOOGLE_FACT_CHECK_API_KEY\")\n",
    "    if not api_key:\n",
    "        return {\n",
    "            \"results\": results,\n",
    "            \"error\": \"Missing GOOGLE_FACT_CHECK_API_KEY. Set it in your environment to use this tool.\",\n",
    "        }\n",
    "\n",
    "    base_url = \"https://factchecktools.googleapis.com/v1alpha1/claims:search\"\n",
    "    params: dict[str, Any] = {\n",
    "        \"query\": query,\n",
    "        \"pageSize\": max(1, min(int(page_size or 10), 50)),\n",
    "        \"key\": api_key,\n",
    "    }\n",
    "    if language_code:\n",
    "        params[\"languageCode\"] = language_code\n",
    "    if page_token:\n",
    "        params[\"pageToken\"] = page_token\n",
    "\n",
    "    next_page_token: str | None = None\n",
    "    try:\n",
    "        async with httpx.AsyncClient(timeout=10.0) as client:\n",
    "            resp = await client.get(base_url, params=params)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json() or {}\n",
    "            next_page_token = data.get(\"nextPageToken\")\n",
    "            for claim in data.get(\"claims\", []) or []:\n",
    "                reviews = []\n",
    "                for r in claim.get(\"claimReview\", []) or []:\n",
    "                    publisher = None\n",
    "                    pub = r.get(\"publisher\") or {}\n",
    "                    if isinstance(pub, dict):\n",
    "                        publisher = pub.get(\"name\")\n",
    "                    reviews.append(\n",
    "                        {\n",
    "                            \"publisher\": publisher,\n",
    "                            \"url\": r.get(\"url\"),\n",
    "                            \"title\": r.get(\"title\"),\n",
    "                            \"reviewDate\": r.get(\"reviewDate\"),\n",
    "                            \"textualRating\": r.get(\"textualRating\"),\n",
    "                            \"languageCode\": r.get(\"languageCode\"),\n",
    "                        }\n",
    "                    )\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"text\": claim.get(\"text\"),\n",
    "                        \"claimant\": claim.get(\"claimant\"),\n",
    "                        \"claimDate\": claim.get(\"claimDate\"),\n",
    "                        \"reviews\": reviews,\n",
    "                    }\n",
    "                )\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        return {\"results\": results, \"error\": f\"HTTP {e.response.status_code}: {e.response.text[:300]}\"}\n",
    "    except Exception as e:\n",
    "        return {\"results\": results, \"error\": f\"Request failed: {e}\"}\n",
    "\n",
    "    out: dict[str, Any] = {\"results\": results}\n",
    "    if next_page_token:\n",
    "        out[\"nextPageToken\"] = next_page_token\n",
    "    return out\n",
    "\n",
    "print(\"Fact check search tool registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rss_tools"
   },
   "source": [
    "### RSS Feed Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rss_helper"
   },
   "outputs": [],
   "source": [
    "DEFAULT_FEED = \"https://feeds.bbci.co.uk/news/technology/rss.xml\"\n",
    "\n",
    "def _norm_entry(entry: Any) -> dict[str, Any]:\n",
    "    title = getattr(entry, \"title\", None) or entry.get(\"title\")\n",
    "    link = getattr(entry, \"link\", None) or entry.get(\"link\")\n",
    "    summary = getattr(entry, \"summary\", None) or entry.get(\"summary\")\n",
    "    published = getattr(entry, \"published\", None) or entry.get(\"published\")\n",
    "    published_iso = None\n",
    "    try:\n",
    "        ts = entry.get(\"published_parsed\")\n",
    "        if ts:\n",
    "            published_iso = dt.datetime(*ts[:6]).isoformat()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"link\": link,\n",
    "        \"summary\": summary,\n",
    "        \"published\": published or published_iso,\n",
    "    }\n",
    "\n",
    "print(\"RSS helper functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rss_tool"
   },
   "outputs": [],
   "source": [
    "@mcp.tool()\n",
    "async def rss_fetch(limit: int = 10) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch and return recent items from the BBC Technology RSS feed.\n",
    "\n",
    "    Args:\n",
    "    - limit: Max number of items to return (1..50). Defaults to 10.\n",
    "\n",
    "    Returns: {\"feed\": {title}, \"items\": [{title, link, summary, published}...]}\n",
    "    \"\"\"\n",
    "    url = DEFAULT_FEED\n",
    "\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (compatible; mcp-rss-tool/1.0; +https://modelcontextprotocol.io)\",\n",
    "            \"Accept\": \"application/rss+xml, application/xml;q=0.9, text/xml;q=0.9, */*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-GB,en;q=0.9\",\n",
    "        }\n",
    "        async with httpx.AsyncClient(timeout=10.0, follow_redirects=True, headers=headers) as client:\n",
    "            resp = await client.get(url)\n",
    "            if resp.status_code != 200:\n",
    "                return {\"items\": [], \"error\": f\"HTTP {resp.status_code}: unable to fetch feed\"}\n",
    "            text = resp.text\n",
    "\n",
    "        parsed = feedparser.parse(text)\n",
    "        bozo = bool(getattr(parsed, \"bozo\", False))\n",
    "        bozo_err = getattr(parsed, \"bozo_exception\", None)\n",
    "\n",
    "        items: list[dict[str, Any]] = []\n",
    "        count = max(1, min(int(limit or 10), 50))\n",
    "        for entry in (parsed.entries or [])[:count]:\n",
    "            items.append(_norm_entry(entry))\n",
    "        feed_title = None\n",
    "        try:\n",
    "            feed_title = getattr(parsed.feed, \"title\", None)\n",
    "        except Exception:\n",
    "            pass\n",
    "        out: dict[str, Any] = {\"feed\": {\"title\": feed_title, \"url\": url}, \"items\": items}\n",
    "        if bozo and not items:\n",
    "            out[\"error\"] = f\"Invalid feed: {bozo_err}\"\n",
    "        elif bozo and items:\n",
    "            out[\"warning\"] = f\"Parse warning: {bozo_err}\"\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        return {\"items\": [], \"error\": f\"Failed to fetch feed: {e}\"}\n",
    "\n",
    "print(\"RSS fetch tool registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guardian_tools"
   },
   "source": [
    "### Guardian API Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guardian_tool"
   },
   "outputs": [],
   "source": [
    "@mcp.tool()\n",
    "async def guardian_search(\n",
    "    query: str,\n",
    "    section: str | None = None,\n",
    "    from_date: str | None = None,\n",
    "    to_date: str | None = None,\n",
    "    page: int = 1,\n",
    "    page_size: int = 10,\n",
    "    order_by: str | None = None,\n",
    "    show_fields: str | None = None,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search the Guardian Content API for articles.\n",
    "\n",
    "    Args:\n",
    "    - query: Search query string. Required.\n",
    "    - section: Optional Guardian section ID (e.g., \"technology\").\n",
    "    - from_date: Optional start date (YYYY-MM-DD).\n",
    "    - to_date: Optional end date (YYYY-MM-DD).\n",
    "    - page: Page number for pagination (>=1). Defaults to 1.\n",
    "    - page_size: Results per page (1..50). Defaults to 10.\n",
    "    - order_by: One of {\"newest\",\"oldest\",\"relevance\"}.\n",
    "    - show_fields: Optional comma-separated fields to include (e.g., \"byline,trailText\").\n",
    "\n",
    "    Returns: {\"results\": [{\"id\",\"title\",\"url\",\"section\",\"published\",\"type\",\"pillar\"}...],\n",
    "              \"pagination\": {\"currentPage\",\"pages\",\"pageSize\",\"total\",\"orderBy\"},\n",
    "              \"nextPage\": optional}\n",
    "\n",
    "    Notes:\n",
    "    - Requires the env var GUARDIAN_API_KEY to be set.\n",
    "    \"\"\"\n",
    "\n",
    "    results: list[dict[str, Any]] = []\n",
    "\n",
    "    if not query or not query.strip():\n",
    "        return {\"results\": results}\n",
    "\n",
    "    api_key = GUARDIAN_API_KEY or os.getenv(\"GUARDIAN_API_KEY\")\n",
    "    if not api_key:\n",
    "        return {\n",
    "            \"results\": results,\n",
    "            \"error\": \"Missing GUARDIAN_API_KEY. Set it in your environment to use this tool.\",\n",
    "        }\n",
    "\n",
    "    base_url = \"https://content.guardianapis.com/search\"\n",
    "    params: dict[str, Any] = {\n",
    "        \"api-key\": api_key,\n",
    "        \"q\": query,\n",
    "        \"page\": max(1, int(page or 1)),\n",
    "        \"page-size\": max(1, min(int(page_size or 10), 50)),\n",
    "    }\n",
    "    if section:\n",
    "        params[\"section\"] = section\n",
    "    if from_date:\n",
    "        params[\"from-date\"] = from_date\n",
    "    if to_date:\n",
    "        params[\"to-date\"] = to_date\n",
    "    if order_by:\n",
    "        params[\"order-by\"] = order_by\n",
    "    if show_fields:\n",
    "        params[\"show-fields\"] = show_fields\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"mcp-guardian-tool/1.0 (+https://modelcontextprotocol.io)\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        async with httpx.AsyncClient(timeout=10.0, headers=headers, follow_redirects=True) as client:\n",
    "            resp = await client.get(base_url, params=params)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json() or {}\n",
    "            response = data.get(\"response\", {})\n",
    "            status = response.get(\"status\")\n",
    "            if status != \"ok\":\n",
    "                message = response.get(\"message\") or status or \"unknown error\"\n",
    "                return {\"results\": results, \"error\": f\"Guardian API error: {message}\"}\n",
    "\n",
    "            for item in response.get(\"results\", []) or []:\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"id\": item.get(\"id\"),\n",
    "                        \"title\": item.get(\"webTitle\"),\n",
    "                        \"url\": item.get(\"webUrl\"),\n",
    "                        \"section\": item.get(\"sectionName\"),\n",
    "                        \"published\": item.get(\"webPublicationDate\"),\n",
    "                        \"type\": item.get(\"type\"),\n",
    "                        \"pillar\": item.get(\"pillarName\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            pagination = {\n",
    "                \"currentPage\": response.get(\"currentPage\"),\n",
    "                \"pages\": response.get(\"pages\"),\n",
    "                \"pageSize\": response.get(\"pageSize\"),\n",
    "                \"total\": response.get(\"total\"),\n",
    "                \"orderBy\": response.get(\"orderBy\"),\n",
    "            }\n",
    "\n",
    "            out: dict[str, Any] = {\"results\": results, \"pagination\": pagination}\n",
    "            try:\n",
    "                cur = int(response.get(\"currentPage\") or 0)\n",
    "                pages = int(response.get(\"pages\") or 0)\n",
    "                if cur and pages and cur < pages:\n",
    "                    out[\"nextPage\"] = cur + 1\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            return out\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        return {\"results\": results, \"error\": f\"HTTP {e.response.status_code}: {e.response.text[:300]}\"}\n",
    "    except Exception as e:\n",
    "        return {\"results\": results, \"error\": f\"Request failed: {e}\"}\n",
    "\n",
    "print(\"Guardian search tool registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "app_setup"
   },
   "source": [
    "## FastAPI App Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "app_cell"
   },
   "outputs": [],
   "source": [
    "app = mcp.streamable_http_app()\n",
    "\n",
    "# Add health and test streaming directly to the MCP app to preserve its lifespan\n",
    "try:\n",
    "    import asyncio\n",
    "    from starlette.responses import StreamingResponse, JSONResponse\n",
    "\n",
    "    if hasattr(app, \"include_router\"):\n",
    "        # FastAPI path\n",
    "        from fastapi import APIRouter\n",
    "\n",
    "        router = APIRouter()\n",
    "\n",
    "        @router.get(\"/healthz\")\n",
    "        async def _healthz() -> dict[str, bool]:\n",
    "            return {\"ok\": True}\n",
    "\n",
    "        async def _event_generator():\n",
    "            while True:\n",
    "                yield \"event: ping\\ndata: ok\\n\\n\"\n",
    "                await asyncio.sleep(1)\n",
    "\n",
    "        @router.get(\"/test-sse\")\n",
    "        async def _test_sse() -> StreamingResponse:\n",
    "            return StreamingResponse(_event_generator(), media_type=\"text/event-stream\")\n",
    "\n",
    "        app.include_router(router)\n",
    "    else:\n",
    "        # Starlette path\n",
    "        async def _healthz(request):\n",
    "            return JSONResponse({\"ok\": True})\n",
    "\n",
    "        async def _event_generator():\n",
    "            while True:\n",
    "                yield \"event: ping\\ndata: ok\\n\\n\"\n",
    "                await asyncio.sleep(1)\n",
    "\n",
    "        async def _test_sse(request):\n",
    "            return StreamingResponse(_event_generator(), media_type=\"text/event-stream\")\n",
    "\n",
    "        app.add_route(\"/healthz\", _healthz)\n",
    "        app.add_route(\"/test-sse\", _test_sse)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"FastAPI app configured with health endpoints!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_tools"
   },
   "source": [
    "## Test the Tools\n",
    "\n",
    "Let's test some of the tools to make sure they're working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_rss"
   },
   "outputs": [],
   "source": [
    "# Test RSS feed (this should work without API keys)\n",
    "import asyncio\n",
    "\n",
    "async def test_rss():\n",
    "    result = await rss_fetch(limit=3)\n",
    "    print(\"RSS Feed Test:\")\n",
    "    print(f\"Feed: {result.get('feed', {}).get('title', 'Unknown')}\")\n",
    "    print(f\"Items found: {len(result.get('items', []))}\")\n",
    "    for i, item in enumerate(result.get('items', [])[:2]):\n",
    "        print(f\"  {i+1}. {item.get('title', 'No title')}\")\n",
    "    if 'error' in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "\n",
    "await test_rss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_guardian"
   },
   "outputs": [],
   "source": [
    "# Test Guardian search (requires API key)\n",
    "async def test_guardian():\n",
    "    result = await guardian_search(\"artificial intelligence\", page_size=3)\n",
    "    print(\"\\nGuardian Search Test:\")\n",
    "    if 'error' in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"Results found: {len(result.get('results', []))}\")\n",
    "        for i, item in enumerate(result.get('results', [])[:2]):\n",
    "            print(f\"  {i+1}. {item.get('title', 'No title')}\")\n",
    "            print(f\"     Section: {item.get('section', 'Unknown')}\")\n",
    "\n",
    "await test_guardian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_server"
   },
   "source": [
    "## Run the Server\n",
    "\n",
    "Now let's run the MCP server. In Colab, we'll use ngrok to expose it publicly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_ngrok"
   },
   "outputs": [],
   "source": [
    "# Install ngrok for public access\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_server"
   },
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Start the server in a separate thread\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=PORT, log_level=\"info\")\n",
    "\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "# Give the server a moment to start\n",
    "time.sleep(3)\n",
    "\n",
    "# Create ngrok tunnel\n",
    "public_url = ngrok.connect(PORT)\n",
    "print(f\"Server is running locally on port {PORT}\")\n",
    "print(f\"Public URL: {public_url}\")\n",
    "print(f\"Health check: {public_url}/healthz\")\n",
    "print(f\"SSE test: {public_url}/test-sse\")\n",
    "print(f\"MCP endpoint: {public_url}/sse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage"
   },
   "source": [
    "## Usage Instructions\n",
    "\n",
    "### MCP Client Connection\n",
    "To connect to this MCP server from an MCP client:\n",
    "\n",
    "1. Use the public URL shown above as your server URL\n",
    "2. The MCP endpoint is at `/sse`\n",
    "3. Authentication is currently disabled for demo purposes\n",
    "\n",
    "### Available Tools\n",
    "\n",
    "1. **search(query)** - Search OpenAI Vector Store\n",
    "2. **fetch(id)** - Fetch full document content\n",
    "3. **fact_check_search(query, language_code, page_size, page_token)** - Google Fact Check API\n",
    "4. **rss_fetch(limit)** - BBC Technology RSS feed\n",
    "5. **guardian_search(query, section, from_date, to_date, page, page_size, order_by, show_fields)** - Guardian API\n",
    "\n",
    "### API Keys Required\n",
    "- **OpenAI API Key**: For vector store search and fetch\n",
    "- **Google Fact Check API Key**: For fact checking\n",
    "- **Guardian API Key**: For news search\n",
    "\n",
    "### Testing the Server\n",
    "You can test the server using curl or any HTTP client:\n",
    "\n",
    "```bash\n",
    "# Health check\n",
    "curl {public_url}/healthz\n",
    "\n",
    "# Test SSE\n",
    "curl {public_url}/test-sse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "When you're done, clean up the ngrok tunnel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup_cell"
   },
   "outputs": [],
   "source": [
    "# Clean up ngrok tunnel\n",
    "ngrok.disconnect(public_url)\n",
    "print(\"Ngrok tunnel disconnected.\")\n",
    "print(\"Server is still running in the background.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}